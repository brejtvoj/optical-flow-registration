import torch


def grad(flow, s):
    """
    Compute gradient of the flow.

    Parameters
    ----------
    flow : Tensor
        Optical flow.
    s : int
        Stride.

    Returns
    -------
    grad_x : Tensor
        Gradient of the flow, in the x direction.
    grad_y : Tensor
        Gradient of the flow, in the y direction.
    """
    f_dy = flow[:, :, s:] - flow[:, :, :-s]
    f_dx = flow[:, :, :, s:] - flow[:, :, :, :-s]
    grad_x = f_dx / s
    grad_y = f_dy / s
    return grad_x, grad_y


def smooth_loss(flow, s, mask=None):
    """
    Calculte smooth loss for the flow tensor.

    Parameteres
    -----------
    flow : Tensor
        Optical flow.
    s : int
        Stride.
    mask : Tensor
        Mask for reduction of the weight of the loss in unimportant areas.
    """
    grad_x, grad_y = grad(flow)
    loss_x = grad_x.abs() / 2.
    loss_y = grad_y.abs() / 2.
    if mask is not None:
        loss_x *= mask
        loss_y *= mask
    return loss_x.mean() + loss_y.mean()


def smooth_loss_sequential(flow_list, mask=None):
    """
    Calculate smooth loss for a serias of flow iterations.

    Parameters
    ----------
    flow_list : list of Tensors
        Flows generated by the RAFT-based network.
    mask : Tensor
        Mask for reduction of the weight of the loss in unimportant areas.

    Returns
    -------
    loss : Tensor
        Comulative loss from the individuall loss calcualtions of each flow.
    """
    loss = 0.0
    gamma = 0.8
    for i in range(len(flow_list) // 2, len(flow_list)):
        i_weight = gamma**(len(flow_list) - i - 1)
        loss_i = smooth_loss(flow_list[i], 1, mask)
        loss += i_weight * loss_i
    return loss
